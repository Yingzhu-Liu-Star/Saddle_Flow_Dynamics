{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d17d5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import odeint\n",
    "import gurobipy as gp \n",
    "from gurobipy import GRB\n",
    "import os\n",
    "\n",
    "np.random.seed(2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46328528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_A_matrix(n):\n",
    "    # 创建基本矩阵块\n",
    "    I_n = np.eye(n)        # n×n 单位矩阵\n",
    "    zero_block = np.zeros((n, n))  # n×n 零矩阵\n",
    "    \n",
    "    # 创建每一行块\n",
    "    # row1 = np.hstack([I_n, -I_n, I_n])      # 第一行: [I_n, -I_n, I_n]\n",
    "    # row2 = np.hstack([zero_block, -I_n, zero_block])  # 第二行: [0, -I_n, 0]\n",
    "    # row3 = np.hstack([zero_block, zero_block, -I_n])  # 第三行: [0, 0, -I_n]\n",
    "    \n",
    "    # 垂直堆叠所有行块\n",
    "    block_matrix = np.block([[I_n, -I_n, I_n], [zero_block, -I_n, zero_block], [zero_block, zero_block, -I_n]])\n",
    "    \n",
    "    return block_matrix\n",
    "\n",
    "def hat_f(x, X, b):\n",
    "    return np.linalg.norm(X@x-b, 2)**2/2.0\n",
    "\n",
    "def grad_hat_f(x, X, b):\n",
    "    return X.T@(X@x-b)\n",
    "\n",
    "def f(x, X, b, lambd, n):\n",
    "    hat_x = x[:n]\n",
    "    bar_x = x[n:]\n",
    "    return np.linalg.norm(X@hat_x-b, 2)**2/2.0+lambd * np.ones(2*n)@bar_x\n",
    "\n",
    "def grad_f(x, X, b, lambd, n):\n",
    "    hat_x = x[:n]\n",
    "    bar_x = x[n:]\n",
    "    hat_grad = X.T@(X@hat_x-b)\n",
    "    bar_grad = lambd * np.ones(2*n)\n",
    "    return np.concatenate([hat_grad, bar_grad], axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71e4796d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7320508075688767 0.2679491924311221 1.0 1.0 16.491425542730166 1.623868484603545e-05 [-1.10766342 -1.94602338 -1.48254958 -2.20816044 -0.49962592] [0.79162115 0.8103383  0.98055723 0.88478525 0.10980113 0.81971076\n",
      " 0.30761289 0.26149467 0.40572354 0.55342038 0.62552644 0.07876025\n",
      " 0.97228343 0.41131105 0.7216644  0.66328748 0.21822526 0.18717254\n",
      " 0.72977924 0.86331326 0.39172036 0.11004811 0.9127915  0.35700599\n",
      " 0.41296218 0.18354969 0.58599027 0.85567085 0.78968122 0.08784242]\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "'''\n",
    "n: dimension of the primal variable\n",
    "m: dimension of the dual variable\n",
    "\n",
    "lf: smoothness parameter of the objective function\n",
    "mf: strong convexity parameter of the objective function\n",
    "\n",
    "alpha: the parameter multiplying the constraint matrix\n",
    "'''\n",
    "\n",
    "n = 5\n",
    "m = n\n",
    "In = np.eye(n)\n",
    "Im = np.eye(m)\n",
    "Bdim = 3*n\n",
    "dim = 6*n\n",
    "time = 800\n",
    "step = 2000\n",
    "time_eval = np.linspace(0,time,step)\n",
    "\n",
    "A = generate_A_matrix(n)\n",
    "large_sigma_A = np.max(np.linalg.eigvals(A @ A.T))\n",
    "small_sigma_A = np.min(np.linalg.eigvals(A @ A.T))      \n",
    "\n",
    "\n",
    "try:\n",
    "    os.makedirs('Para', exist_ok=True)\n",
    "    \n",
    "    X = np.load('Para/matrix_X.npy')\n",
    "    b = np.load('Para/vector_b.npy')\n",
    "    w0 = np.load('Para/vector_x0.npy')\n",
    "    lambd = np.load('Para/lambd.npy')\n",
    "\n",
    "    lf = np.linalg.eigvalsh(X @ X.T).max()\n",
    "    mf = np.linalg.eigvalsh(X @ X.T).min()\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"Error:Not Find Parameters\")\n",
    "\n",
    "B = np.eye(3*n)\n",
    "large_sigma_B = np.max(np.linalg.eigvals(B @ B.T))\n",
    "small_sigma_B = np.min(np.linalg.eigvals(B @ B.T))\n",
    "\n",
    "alpha = 4.0/lf\n",
    "eta = 1.0\n",
    "rho = 1.0\n",
    "print(large_sigma_A,small_sigma_A,large_sigma_B,small_sigma_B, lf, mf, b, w0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c3e4c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2026-02-19\n",
      "[-2.83697848e-08 -5.89781782e-01 -3.19751533e-09 -2.43868534e-10\n",
      " -7.96403353e-11  2.79790601e-12  2.79717345e-12  2.89320527e-12\n",
      "  3.10171256e-12  3.29209308e-12  2.83725832e-08  5.89781782e-01\n",
      "  3.20040895e-09  2.46971604e-10  8.29324290e-11] \n",
      " [-3.95788639 -4.         -3.63690454 -2.865819   -3.44762093  7.95788639\n",
      "  8.          7.63690454  6.865819    7.44762093  0.04211361  0.\n",
      "  0.36309546  1.134181    0.55237907]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# compute the optimal solution to the equivalent form of Lasso regression problem\n",
    "def gurobi_transformed_lasso(X, b, lambd):\n",
    "    dim = 3*n\n",
    "    model = gp.Model(\"gp\")\n",
    "    model.setParam('OutputFlag', 0)\n",
    "    model.Params.Threads = 0 \n",
    "    u = model.addMVar(dim, lb=-gp.GRB.INFINITY, name='u')\n",
    "\n",
    "\n",
    "    hat_x = u[:n]\n",
    "    bar_x = u[n:]\n",
    "    obj = 0.5 * ((X@hat_x-b)@(X@hat_x-b)).sum() + lambd*np.ones(2*n)@bar_x\n",
    "    # set objective\n",
    "    model.setObjective(obj, GRB.MINIMIZE)\n",
    "    # set constraints\n",
    "    I = np.eye(n)\n",
    "    # B = np.block([-I, I])\n",
    "    model.addConstr(hat_x - u[n:2*n] + u[2*n:3*n] == 0)\n",
    "    model.addConstr(u[n:] >= 0)\n",
    "\n",
    "    model.update()\n",
    "    model.optimize()\n",
    "\n",
    "    u_opt = np.zeros(dim)\n",
    "    v_opt = np.zeros(dim)\n",
    "    if model.status == GRB.OPTIMAL:\n",
    "        # Access the optimal variable values\n",
    "        for i in range(dim):\n",
    "            u_opt[i] = model.getVarByName('u[{}]'.format(i)).X\n",
    "    else:\n",
    "        print(\"Optimization did not converge to an optimal solution.\")\n",
    "    flag = 0\n",
    "    for con in model.getConstrs():\n",
    "        v_opt[flag] = con.Pi\n",
    "        flag += 1\n",
    "    v_opt[:n] = -v_opt[:n]\n",
    "    return model.objVal, u_opt, v_opt\n",
    "\n",
    "f_opt, x_opt, y_opt = gurobi_transformed_lasso(X,b,lambd)\n",
    "print(x_opt,\"\\n\", y_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "654ad8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-116.59547707  -29.59849378  177.76123521   74.0178565   -83.33830612] \n",
      " [-0. -0. -0. -0. -0.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# compute the optimal solution to the equivalent form of Lasso regression problem\n",
    "def LeastSquare(X,b):\n",
    "    dim = n\n",
    "    model = gp.Model(\"gp\")\n",
    "    model.setParam('OutputFlag', 0)\n",
    "    model.Params.Threads = 0 \n",
    "    u = model.addMVar(dim, lb=-gp.GRB.INFINITY, name='u')\n",
    "\n",
    "    obj = 0.5 * ((X@u-b)@(X@u-b)).sum() \n",
    "    model.setObjective(obj, GRB.MINIMIZE)\n",
    "\n",
    "    model.update()\n",
    "    model.optimize()\n",
    "\n",
    "    u_opt = np.zeros(dim)\n",
    "    v_opt = np.zeros(dim)\n",
    "    if model.status == GRB.OPTIMAL:\n",
    "        # Access the optimal variable values\n",
    "        for i in range(dim):\n",
    "            u_opt[i] = model.getVarByName('u[{}]'.format(i)).X\n",
    "    else:\n",
    "        print(\"Optimization did not converge to an optimal solution.\")\n",
    "    flag = 0\n",
    "    for con in model.getConstrs():\n",
    "        v_opt[flag] = con.Pi\n",
    "        flag += 1\n",
    "    v_opt[:n] = -v_opt[:n]\n",
    "    return model.objVal, u_opt, v_opt\n",
    "\n",
    "hat_f_opt, hat_x_opt, hat_y_opt = LeastSquare(X,b)\n",
    "print(hat_x_opt,\"\\n\", hat_y_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d21f0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the intermediate variable p_star\n",
    "def cal_p_star(A, b, X, B, u, v, alpha, rho):\n",
    "    dim =3*n\n",
    "    B_inv = np.linalg.inv(B)\n",
    "    model = gp.Model('qp')\n",
    "    model.setParam('OutputFlag', 0)\n",
    "    model.Params.Threads = 0 \n",
    "    p = model.addMVar(dim, lb=-GRB.INFINITY, name='p')\n",
    "    model.addConstr(p[n:] >= 0)\n",
    "    \n",
    "    tilde_x = u-alpha*A.T@B_inv@p\n",
    "    hat_x = tilde_x[:n]\n",
    "    bar_x = tilde_x[n:]\n",
    "    obj = 0\n",
    "    obj += 0.5 * ((X @ hat_x - b) @ (X @ hat_x - b)) + lambd * (np.ones(2*n) @ bar_x)                  # linear term\n",
    "    obj +=  p @ (B_inv.T @ A @ u)                # linear term\n",
    "    obj += - alpha * ((A.T @ B_inv @ p) @ (A.T @ B_inv @ p))  # quadratic term\n",
    "    obj += - rho/2.0 * ((p - v) @ (p - v))                 # quadratic term\n",
    "\n",
    "    # Add the scalar f_val to the Gurobi expression\n",
    "    model.setObjective(obj, GRB.MAXIMIZE)\n",
    "    model.optimize()\n",
    "\n",
    "    p_opt = p.x\n",
    "\n",
    "    return p_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05919861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dynamics\n",
    "'''\n",
    "'''\n",
    "def dynamic(x, t, alpha, rho):\n",
    "    u,v = x[:3*n],x[3*n:]\n",
    "    p_star = cal_p_star(A, b, X, B, u, v, alpha, rho)\n",
    "    # print(p_star)\n",
    "    B_inv = np.linalg.inv(B)\n",
    "\n",
    "    du = - grad_f(u-alpha*A.T@B_inv@p_star, X, b, lambd, n) - A.T@B_inv@p_star\n",
    "    dv = rho*(p_star-v)\n",
    "\n",
    "    # \\bar_y should be non-positive\n",
    "    for i in range(2*n):\n",
    "        if v[n+i] <= 0:\n",
    "            dv[n+i] = max(0, dv[n+i])\n",
    "    dynamics = np.concatenate((du, dv)).reshape(6*n).tolist()\n",
    "    # print(dynamics)\n",
    "    return dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "006a0569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results\n",
    "res = []\n",
    "t = np.linspace(0,time,step)\n",
    "res = odeint(dynamic, w0, t, args=(alpha, rho))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96edaf92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [-1.67174970e-07 -5.89781649e-01 -7.33273442e-11 -2.04691819e-11\n",
      " -4.67829109e-11  3.59257069e-12  3.51851881e-12  3.72901710e-12\n",
      "  4.12536671e-12  3.81517040e-12  1.67178645e-07  5.89781649e-01\n",
      "  7.71116504e-11  2.46259679e-11  5.06409359e-11]\n",
      "y: [-3.95788637e+00 -4.00000000e+00 -3.63690453e+00 -2.86581899e+00\n",
      " -3.44762092e+00  7.95788637e+00  8.00000000e+00  7.63690453e+00\n",
      "  6.86581899e+00  7.44762092e+00  4.21136309e-02  4.73656478e-11\n",
      "  3.63095467e-01  1.13418101e+00  5.52379077e-01]\n",
      "x_orig_opt (-7.403270201322698e-06, array([-116.59547707,  -29.59849378,  177.76123521,   74.0178565 ,\n",
      "        -83.33830612]), array([-0., -0., -0., -0., -0.]))\n",
      "x_opt: [-2.83697848e-08 -5.89781782e-01 -3.19751533e-09 -2.43868534e-10\n",
      " -7.96403353e-11  2.79790601e-12  2.79717345e-12  2.89320527e-12\n",
      "  3.10171256e-12  3.29209308e-12  2.83725832e-08  5.89781782e-01\n",
      "  3.20040895e-09  2.46971604e-10  8.29324290e-11]\n",
      "y_opt: [-3.95788639 -4.         -3.63690454 -2.865819   -3.44762093  7.95788639\n",
      "  8.          7.63690454  6.865819    7.44762093  0.04211361  0.\n",
      "  0.36309546  1.134181    0.55237907]\n",
      "f(x):  5.460607183129879\n",
      "f_opt:  5.460607178658021\n"
     ]
    }
   ],
   "source": [
    "x_orig_opt = LeastSquare(X,b)\n",
    "f_opt, x_opt, y_opt= gurobi_transformed_lasso(X, b, lambd)\n",
    "solution =res[-1]\n",
    "u_opt = solution[:3*n]\n",
    "v_opt = solution[3*n:]\n",
    "x = u_opt - alpha * A.T @ np.linalg.inv(B) @ v_opt\n",
    "y = np.linalg.inv(B) @ v_opt\n",
    "# Double check \n",
    "print('x:',x)\n",
    "print('y:',y)\n",
    "print('x_orig_opt',x_orig_opt)\n",
    "print('x_opt:',x_opt)\n",
    "print('y_opt:',y_opt)\n",
    "print(\"f(x): \", f(x, X, b, lambd, n))\n",
    "print(\"f_opt: \", f(x_opt, X, b, lambd, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a327cb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "now = datetime.datetime.now()\n",
    "# Pickling the object\n",
    "Storage = {'result':res,'rho': rho, 'alpha': alpha, 'lambd': lambd,'X_matrix': X, 'time': time, 'step': step, 'time_step': time_eval, 'n': n, 'x_opt': x_opt, 'y_opt': y_opt, 'l':lf}\n",
    "with open('Result/results_{}_parameters.pkl'.format(now), 'wb') as file:\n",
    "    pickle.dump(Storage, file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
